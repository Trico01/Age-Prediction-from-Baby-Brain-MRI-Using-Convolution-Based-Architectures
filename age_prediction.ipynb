{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import glob\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from utils.functions import fix_seed\n",
    "from utils.datasets import DatasetBCP_T_2D\n",
    "from utils.train import train\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from models.Conv2D import Conv2D\n",
    "from models.Res2D import Res2D\n",
    "from models.Conv_ASPP import ConvASPP\n",
    "from models.Conv_Attention import ConvAttention\n",
    "import nibabel as nib\n",
    "from nibabel.processing import conform\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--modality\", type=str, default=\"T2\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "parser.add_argument(\"--lr\", type=float, default=5e-4)\n",
    "parser.add_argument(\"--epochs\", type=int, default=300)\n",
    "parser.add_argument(\"--seed\", type=int, default=42)\n",
    "parser.add_argument(\"--gpu\", type=list, default=[0,1])\n",
    "parser.add_argument(\"--use_amp\", type=bool, default=True) # gradscalar\n",
    "opt = parser.parse_args([])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\", opt.gpu[0]) if torch.cuda.is_available() else \"cpu\"\n",
    "fix_seed(opt.seed)\n",
    "\n",
    "# make directory\n",
    "PATH = \"/home/yshuai/age_predict/\" + f\"{opt.modality}\"\n",
    "os.makedirs(PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution\n",
    "file_paths = sorted(glob.glob(\"/home/yshuai/age_predict/data/BCP/T1/*.nii.gz\", recursive=True))\n",
    "labels1=[]\n",
    "for file_path in file_paths:\n",
    "    file_name=os.path.basename(file_path)\n",
    "    match = re.search(r'_(\\d+)',file_name)\n",
    "    if match:\n",
    "        label = int(match.group(1))\n",
    "        labels1.append(label)\n",
    "\n",
    "file_paths = sorted(glob.glob(\"/home/yshuai/age_predict/data/BCP/T2/*.nii.gz\", recursive=True))\n",
    "labels2=[]\n",
    "for file_path in file_paths:\n",
    "    file_name=os.path.basename(file_path)\n",
    "    match = re.search(r'_(\\d+)',file_name)\n",
    "    if match:\n",
    "        label = int(match.group(1))\n",
    "        labels2.append(label)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(labels1, bins=range(0,25,1), label='T1', alpha=0.6, edgecolor='black')\n",
    "plt.hist(labels2, bins=range(0,25,1), label='T2', alpha=0.8, edgecolor='black')\n",
    "plt.title('Age Distribution',fontsize=17)\n",
    "plt.xlabel('Month Age',fontsize=14)\n",
    "plt.ylabel('Number of scans',fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.savefig('dist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read T2 data\n",
    "file_paths = sorted(glob.glob(\"/home/yshuai/age_predict/data/BCP/T2/*.nii.gz\", recursive=True))\n",
    "voxels=[]\n",
    "labels=[]\n",
    "print('----- Reading Data -----')\n",
    "for file_path in tqdm(file_paths):\n",
    "    voxel = nib.squeeze_image(nib.as_closest_canonical(nib.load(file_path)))\n",
    "    voxel = conform(voxel, (208, 300, 320), voxel_size=(0.8, 0.8, 0.8), order=1)\n",
    "    voxel = voxel.get_fdata().astype(np.float32)\n",
    "    voxels.append(voxel)\n",
    "\n",
    "    file_name=os.path.basename(file_path)\n",
    "    match = re.search(r'_(\\d+)',file_name)\n",
    "    if match:\n",
    "        label = int(match.group(1))\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "dataset = DatasetBCP_T_2D(voxels,labels,mode='cc')\n",
    "del voxels,labels\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.6)\n",
    "test_size = dataset_size - train_size\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size])\n",
    "val_size = int(dataset_size * 0.2)\n",
    "test_size = test_size - val_size\n",
    "val_set, test_set = random_split(test_set, [val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "num_workers = 0\n",
    "train_loader = DataLoader(train_set, batch_size=opt.batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=opt.batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "model = Conv2D(1)\n",
    "# model = Res2D(1,1,[2,2,2,2])\n",
    "# model=ConvAttention(1,208,300)\n",
    "# model=ConvASPP(1,208,300)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=opt.epochs, eta_min=0.00001)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "scaler = GradScaler(enabled=opt.use_amp)\n",
    "\n",
    "# train\n",
    "print('----- Start Training -----')\n",
    "best_model_dict=train(PATH,model,optimizer,scheduler,criterion,scaler,device,opt.epochs,train_loader,val_loader,use_amp=opt.use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "dataset.is_test=True\n",
    "dataset.mode='cc'\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "test_loss=0\n",
    "best_model=Conv2D(1)\n",
    "# best_model=ConvAttention(1,208,300)\n",
    "# best_model=ConvASPP(1,208,300)\n",
    "# best_model=Res2D(1,1,[2,2,2,2])\n",
    "\n",
    "best_model.load_state_dict(torch.load('T2/cnn_cc_model.pth'))\n",
    "best_model.to(device)\n",
    "best_model.eval()\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images=images.permute(1,0,2,3)\n",
    "    labels=(labels.unsqueeze(1)).repeat(images.shape[0],1).squeeze()\n",
    "    images,labels=images.to(device),labels.to(device)\n",
    "    images=images.to(device)\n",
    "    outputs=best_model(images)\n",
    "    loss=criterion(outputs,labels)\n",
    "    test_loss+=loss.item()\n",
    "    \n",
    "test_loss/=len(test_loader)\n",
    "print(f'Test MAE Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradcam\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import BinaryClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "dataset.is_test=True\n",
    "dataset.mode='cc'\n",
    "subject=17\n",
    "images,labels=test_set[subject][0].unsqueeze(1), test_set[subject][1]\n",
    "print(f'Subject age = {labels.item()}')\n",
    "\n",
    "# plot original image\n",
    "fig, axs = plt.subplots(1, 8, figsize=(20, 5))\n",
    "for i in range(8):\n",
    "    ax=axs[i]\n",
    "    ax.imshow(np.rot90(np.stack([(images[10+4*i][0]).cpu().numpy()]*3,axis=-1)/2+0.5))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(f'z={170+10+4*i}',fontsize=13)\n",
    "    if i==0:\n",
    "        ax.set_ylabel('Original',fontsize=14)\n",
    "plt.savefig('original.png')\n",
    "\n",
    "# plot gradcam image\n",
    "best_model = Conv2D(1)\n",
    "best_model.load_state_dict(torch.load('T2/cnn_cc_model.pth'))\n",
    "images=images.to(device)\n",
    "target_layers=[best_model.conv5]\n",
    "targets=[BinaryClassifierOutputTarget(1)]\n",
    "cam=GradCAM(model=best_model,target_layers=target_layers)\n",
    "fig, axs = plt.subplots(1, 8, figsize=(20, 5))\n",
    "for i in range(8):\n",
    "    ax=axs[i]\n",
    "    grayscale_cam=cam(input_tensor=images[10+4*i].unsqueeze(0),targets=targets)\n",
    "    visualization=show_cam_on_image(np.stack([(images[10+4*i][0]).cpu().numpy()]*3,axis=-1)/2+0.5,grayscale_cam[0],use_rgb=True)\n",
    "    ax.imshow(np.rot90(visualization))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(f'z={170+10+4*i}',fontsize=13)\n",
    "    if i==0:\n",
    "        ax.set_ylabel('CNN',fontsize=14)\n",
    "plt.savefig('cnn_cc_grad.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
